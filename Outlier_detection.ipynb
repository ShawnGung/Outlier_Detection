{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer #dictionary vectorization\n",
    "from imblearn.over_sampling import SMOTE #upsampleing SMOTE\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score #cross validation\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, BaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic summary of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_summary(df):\n",
    "    print('{:-^60}'.format('Data overview:'))\n",
    "    print(df.tail(2))\n",
    "    print('{:-^60}'.format('Data dtypes:'))\n",
    "    print(df.dtypes)\n",
    "    print('{:-^60}'.format('Data DESC:'))\n",
    "    print(df.describe().round(2).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def na_summary(df):\n",
    "    '''\n",
    "    find nan value in data\n",
    "    :param df: dataframe\n",
    "    :return: \n",
    "    '''\n",
    "    na_cols = df.isnull().any(axis=0) \n",
    "    print('{:-^60}'.format('NA cols:'))\n",
    "    print(na_cols)\n",
    "    na_lines = df.isnull().any(axis=1) \n",
    "    print('Total number of NA lines is: {0}'.format(na_lines.sum()))\n",
    "    \n",
    "def label_samples_summary(df):\n",
    "    '''\n",
    "    show the labels count\n",
    "    :param df: dataframe\n",
    "    :return: 无\n",
    "    '''\n",
    "    print('{:-^60}'.format('Labels samples count:'))\n",
    "    print(df.iloc[:,-1].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function to turn string into discrete value and store in dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#字符串分类转整数分类，用于将分类变量中的字符串转换为数值索引分类。为了能够进行矩阵计算，需要将字符串的分类变量转换为数值型分类变量。\n",
    "def str2int(set, convert_object, unique_object, training=True):\n",
    "    '''\n",
    "    将分类变量中的字符串转换为数值索引分类\n",
    "    :param set: 数据集\n",
    "    :param convert_object: DictVectorizer转换对象，当training为true时为空；当training为false时则从训练阶段得到的对象\n",
    "    :param unique_object: 唯一值列表，当training为true时为空；当training为false时则从训练阶段得到唯一值列表\n",
    "    :training: 是否为训练阶段\n",
    "    :return: 训练阶段返回model_dvtransform, unique_list,train_part_data;预测阶段返回predict_part_data\n",
    "    '''\n",
    "    convert_cols = ['cat','attribution','pro_id','pro_brand','order_source','pay_type','use_id','city']\n",
    "    final_convert_matrix = set[convert_cols] #获得要转换的数据集合\n",
    "    #final_convert_matrix , 某几个column的数据集合\n",
    "    \n",
    "    lines = set.shape[0]\n",
    "    dict_list = [] #总空列表，用于存放字符串与对应索引组成的字典\n",
    "    if training == True:#训练阶段\n",
    "        unique_list = [] #总唯一值列表，用于存放每列唯一值\n",
    "        for col_name in convert_cols: #循环读取每个列\n",
    "            cols_unique_value = set[col_name].unique().tolist() #获取列的唯一值列表\n",
    "            unique_list.append(cols_unique_value) #将唯一值列表追加到总列表\n",
    "        #unique_list 包含每个特征的所有unique的值列表 [[], [] , []]\n",
    "        for line_index in range(lines): #读取每行索引\n",
    "            each_record = final_convert_matrix.iloc[line_index] #获取每行数据\n",
    "            #each_record : 每行数据\n",
    "            \n",
    "            for each_index, each_data in enumerate(each_record): #读取每行对应的索引值\n",
    "                list_value = unique_list[each_index] #查找唯一值在列表中的位置\n",
    "                #list_value是each_index的特征下的所有唯一值列表\n",
    "                each_record[each_index] = list_value.index(each_data)#将每个值映射成唯一值的索引\n",
    "                #list_value.index(each_data) 是这个属性值在唯一值列表中的index\n",
    "            \n",
    "            #columns名字与column中存的字符串对应的unique index 组成字典\n",
    "            each_dict = dict(zip(convert_cols, each_record))#将每个值与对应的索引组成字典\n",
    "            dict_list.append(each_dict)#将字典追加到总列表\n",
    "        model_dvtransform = DictVectorizer(sparse=False, dtype=np.int64)#建立转换模型对象\n",
    "        model_dvtransform.fit(dict_list)#应用分类转换训练\n",
    "        train_part_data = model_dvtransform.transform(dict_list)#转换训练集\n",
    "        return model_dvtransform, unique_list, train_part_data\n",
    "        '''\n",
    "        最后输出一个与输入matrix类似的,但是里面的值换成了对应unique_list中的index\n",
    "        '''\n",
    "    \n",
    "    else:\n",
    "        for line_index in range(lines):\n",
    "            each_record = final_convert_matrix.iloc[line_index]\n",
    "            for each_index, each_data in enumerate(each_record):\n",
    "                list_value = unique_object[each_index]\n",
    "                each_record[each_index] = list_value.index(each_data)\n",
    "            each_dict = dict(zip(convert_cols,each_record))\n",
    "            dict_list.append(each_dict)\n",
    "        predict_part_data = convert_object.transform(dict_list)\n",
    "        return predict_part_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### turn time into different parts as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time attribute expanding\n",
    "def datetime2int(set):\n",
    "    '''\n",
    "    将日期和时间数据拓展出其他属性，例如星期几、周几、小时、分钟等。\n",
    "    :param set: 数据集\n",
    "    :return: 拓展后的属性矩阵\n",
    "    '''\n",
    "    date_set = list(map(lambda dates: pd.datetime.strptime(dates, '%Y-%m-%d'), set['order_date']))\n",
    "    weekday_data = list(map(lambda data: data.weekday(), date_set)) #week\n",
    "    daysinmonth_data = list(map(lambda data: data.day, date_set)) #date\n",
    "    month_data = list(map(lambda data: data.month, date_set)) #month\n",
    "    \n",
    "    time_set = list(map(lambda times: pd.datetime.strptime(times, '%H:%M:%S'), set['order_time']))\n",
    "    second_data = list(map(lambda data: data.second, time_set)) #sec\n",
    "    minute_data = list(map(lambda data: data.minute, time_set)) #min\n",
    "    hour_data = list(map(lambda data: data.hour, time_set)) #hour\n",
    "    \n",
    "    final_set = [] \n",
    "    final_set.extend((weekday_data, daysinmonth_data, month_data, second_data, minute_data, hour_data))\n",
    "    final_matrix = np.array(final_set).T \n",
    "    return final_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### upsample of minority abnormal orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_balance(X, y):\n",
    "    '''\n",
    "    :param X: input\n",
    "    :param y: label\n",
    "    :return: balacend X,y\n",
    "    '''\n",
    "    model_smote = SMOTE() \n",
    "    x_smote_resampled, y_smote_resampled = model_smote.fit_resample(X, y) \n",
    "    return x_smote_resampled, y_smote_resampled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {'order_id': np.object,\n",
    "          'pro_id': np.object,\n",
    "          'use_id': np.object}\n",
    "raw_data = pd.read_table('data/abnormal_orders.txt', delimiter=',', dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Data overview:-----------------------\n",
      "          order_id  order_date order_time       cat attribution      pro_id  \\\n",
      "134188  4285770012  2013-09-19   23:55:06      家居日用          GO  1000335947   \n",
      "134189  4285770056  2013-05-20   23:58:59  生活电器厨卫电器          GO  1000009280   \n",
      "\n",
      "       pro_brand  total_money  total_quantity order_source pay_type  \\\n",
      "134188       炊大师         79.0               1           抢购     合并支付   \n",
      "134189        海尔        799.0               1           抢购     合并支付   \n",
      "\n",
      "            use_id city  abnormal_label  \n",
      "134188      shukun  东莞市               0  \n",
      "134189  544975322_  海口市               0  \n",
      "------------------------Data dtypes:------------------------\n",
      "order_id           object\n",
      "order_date         object\n",
      "order_time         object\n",
      "cat                object\n",
      "attribution        object\n",
      "pro_id             object\n",
      "pro_brand          object\n",
      "total_money       float64\n",
      "total_quantity      int64\n",
      "order_source       object\n",
      "pay_type           object\n",
      "use_id             object\n",
      "city               object\n",
      "abnormal_label      int64\n",
      "dtype: object\n",
      "-------------------------Data DESC:-------------------------\n",
      "                   count    mean      std  min   25%   50%    75%       max\n",
      "total_money     134189.0  660.11  2901.21  0.5  29.0  98.4  372.0  766000.0\n",
      "total_quantity  134190.0    1.20     3.23  1.0   1.0   1.0    1.0    1000.0\n",
      "abnormal_label  134190.0    0.21     0.41  0.0   0.0   0.0    0.0       1.0\n"
     ]
    }
   ],
   "source": [
    "set_summary(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------NA cols:--------------------------\n",
      "order_id          False\n",
      "order_date        False\n",
      "order_time        False\n",
      "cat                True\n",
      "attribution       False\n",
      "pro_id            False\n",
      "pro_brand          True\n",
      "total_money        True\n",
      "total_quantity    False\n",
      "order_source      False\n",
      "pay_type          False\n",
      "use_id            False\n",
      "city               True\n",
      "abnormal_label    False\n",
      "dtype: bool\n",
      "Total number of NA lines is: 1429\n"
     ]
    }
   ],
   "source": [
    "na_summary(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Labels samples count:--------------------\n",
      "0    105733\n",
      "1     28457\n",
      "Name: abnormal_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_samples_summary(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_na_set = raw_data.dropna() #throw those row with nan value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = drop_na_set.iloc[:, 1:-1] #throw id column and the label column\n",
    "y_raw = drop_na_set.iloc[:, -1]   #extract the label column\n",
    "model_dvtransform, unique_object, str2int_data = str2int(X_raw, None, None, training=True) #turn string into int\n",
    "datetime2int_data = datetime2int(X_raw) #expand the time attribute\n",
    "combine_set = np.hstack((str2int_data, datetime2int_data))\n",
    "constant_set = X_raw[['total_money','total_quantity']] \n",
    "X_combine = np.hstack((combine_set, constant_set))\n",
    "X, y = sample_balance(X_combine, y_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### having same data size in different labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 104477, 0: 104477})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "labelCnt = Counter(y)\n",
    "print(labelCnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Cross val score:----------------------\n",
      "[0.71803216 0.89218989 0.96550536 0.97695253 0.93514548 0.91856191\n",
      " 0.92128034 0.92522398]\n",
      "Mean scores is: 0.91\n"
     ]
    }
   ],
   "source": [
    "#randomForest\n",
    "model_rf = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "cv = StratifiedKFold(8)\n",
    "cv_score = cross_val_score(model_rf, X, y, cv=cv)\n",
    "print('{:-^60}'.format('Cross val score:'))\n",
    "print(cv_score)\n",
    "print('Mean scores is: %.2f' % cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Cross val score:----------------------\n",
      "[0.68158499 0.87672282 0.91347626 0.88223583 0.81619449 0.83620492\n",
      " 0.82743702 0.84416877]\n",
      "Mean scores is: 0.83\n"
     ]
    }
   ],
   "source": [
    "#logistic\n",
    "model_lr = LogisticRegression(random_state=0)\n",
    "cv = StratifiedKFold(8)\n",
    "cv_score = cross_val_score(model_lr, X, y, cv=cv)\n",
    "print('{:-^60}'.format('Cross val score:'))\n",
    "print(cv_score)\n",
    "print('Mean scores is: %.2f' % cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Cross val score:----------------------\n",
      "[0.68139357 0.83212098 0.9611026  0.97745023 0.93491577 0.91990198\n",
      " 0.92503254 0.92660234]\n",
      "Mean scores is: 0.89\n"
     ]
    }
   ],
   "source": [
    "#bagging\n",
    "model_BagC = BaggingClassifier(n_estimators=20, random_state=0)\n",
    "cv = StratifiedKFold(8)\n",
    "cv_score = cross_val_score(model_BagC, X, y, cv=cv)\n",
    "print('{:-^60}'.format('Cross val score:'))\n",
    "print(cv_score)\n",
    "print('Mean scores is: %.2f' % cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Cross val score:----------------------\n",
      "[0.77411945 0.92557427 0.97293262 0.97117152 0.9257657  0.90906654\n",
      " 0.90929627 0.91526916]\n",
      "Mean scores is: 0.91\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('randomforest', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "        ...estimators=20, n_jobs=None, oob_score=False, random_state=0,\n",
       "         verbose=0, warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=-1, voting='soft',\n",
       "         weights=[0.9, 1.2, 1.1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#randomforest,logistic,bagging,voting classifier\n",
    "model_rf = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "model_lr = LogisticRegression(random_state=0)\n",
    "model_BagC = BaggingClassifier(n_estimators=20, random_state=0)\n",
    "estimators = [('randomforest', model_rf),('Logistic', model_lr),('bagging', model_BagC)]\n",
    "model_vot = VotingClassifier(estimators=estimators, voting='soft', weights=[0.9, 1.2, 1.1], n_jobs=-1)\n",
    "cv = StratifiedKFold(8)\n",
    "cv_score = cross_val_score(model_vot, X, y, cv=cv)\n",
    "print('{:-^60}'.format('Cross val score:'))\n",
    "print(cv_score)\n",
    "print('Mean scores is: %.2f' % cv_score.mean())\n",
    "model_vot.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------Predicted Labels:----------------------\n",
      "[1 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "X_raw_data = pd.read_csv('data/new_abnormal_orders.csv', dtype=dtypes)\n",
    "X_raw_new = X_raw_data.iloc[:, 1:]\n",
    "str2int_data_new = str2int(X_raw_data, model_dvtransform, unique_object, training=False)\n",
    "datetime2int_data_new = datetime2int(X_raw_new)\n",
    "combine_set_new = np.hstack((str2int_data_new, datetime2int_data_new))\n",
    "constant_set_new = X_raw_data[['total_money','total_quantity']]\n",
    "X_combine_new = np.hstack((combine_set_new, constant_set_new))\n",
    "y_predict = model_vot.predict(X_combine_new)\n",
    "print('{:-^60}'.format('Predicted Labels:'))\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one class SVM\n",
    "X_white = drop_na_set.loc[drop_na_set['abnormal_label'] == 0] #all normal dataset\n",
    "X_abnormal = drop_na_set.loc[drop_na_set['abnormal_label'] == 1] #all normal dataset\n",
    "\n",
    "X_white_raw = X_white.iloc[:, 1:-1] \n",
    "y_white_raw = X_white.iloc[:, -1]   \n",
    "\n",
    "X_abnormal_raw = X_abnormal.iloc[:, 1:-1] \n",
    "y_abnormal_raw = X_abnormal.iloc[:, -1]   \n",
    "\n",
    "\n",
    "str2int_data = str2int(X_white_raw, model_dvtransform, unique_object, training=False) \n",
    "datetime2int_data = datetime2int(X_white_raw) \n",
    "combine_set = np.hstack((str2int_data, datetime2int_data)) \n",
    "constant_set = X_white_raw[['total_money','total_quantity']] \n",
    "X_white_changed = np.hstack((combine_set, constant_set)) \n",
    "\n",
    "str2int_data = str2int(X_abnormal_raw, model_dvtransform, unique_object, training=False) \n",
    "datetime2int_data = datetime2int(X_abnormal_raw) \n",
    "combine_set = np.hstack((str2int_data, datetime2int_data)) \n",
    "constant_set = X_abnormal_raw[['total_money','total_quantity']] \n",
    "X_abnormal_changed = np.hstack((combine_set, constant_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 568.980211019516\n",
      "n_normal_acc: 0.28391894866812795\n",
      "n_abnormal_acc: 1.0\n",
      "precision: 0.2743409183495315\n",
      "recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "clf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma='auto')\n",
    "clf.fit(X_white_changed[:50000])\n",
    "y_pred_white = clf.predict(X_white_changed)\n",
    "y_pred_abnormal = clf.predict(X_abnormal_changed)\n",
    "n_error_train = y_pred_white[y_pred_white == -1].size\n",
    "n_error_test = y_pred_abnormal[y_pred_abnormal == 1].size\n",
    "print('time:',time.time() - start)\n",
    "print('n_normal_acc:',1 - (n_error_train / len(y_pred_white)))\n",
    "print('n_abnormal_acc:',1 - (n_error_test / len(y_pred_abnormal)))\n",
    "TP = len(y_pred_abnormal) - n_error_test\n",
    "FN = n_error_test\n",
    "FP = n_error_train\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "print('precision:',precision)\n",
    "print('recall:',recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------Predicted Labels:----------------------\n",
      "[-1  1  1  1  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "X_raw_data = pd.read_csv('data/new_abnormal_orders.csv', dtype=dtypes)\n",
    "X_raw_new = X_raw_data.iloc[:, 1:]\n",
    "str2int_data_new = str2int(X_raw_data, model_dvtransform, unique_object, training=False)\n",
    "datetime2int_data_new = datetime2int(X_raw_new)\n",
    "combine_set_new = np.hstack((str2int_data_new, datetime2int_data_new))\n",
    "constant_set_new = X_raw_data[['total_money','total_quantity']]\n",
    "X_combine_new = np.hstack((combine_set_new, constant_set_new))\n",
    "y_predict = clf.predict(X_combine_new)\n",
    "print('{:-^60}'.format('Predicted Labels:'))\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
